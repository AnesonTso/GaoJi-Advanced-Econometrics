{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1 Foundation of Probability Theory Part IV\n",
    "\n",
    "#### *Zhuo Jianchao* \n",
    "\n",
    "Feb 6, 2020 *Rev 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a simulation game, you play the mayor of a town. And this video game has four weather conditions being sunny, cloudy, rainy and stormy. The weather forecast department will call you at the morning if their forecast of the day is rainy or stormy. Everyday the weather is random with the same likelihood. One of the four setting must occur, so the probability of a day being rainy is $\\frac{1}{4}$. Is it?\n",
    "\n",
    "No. Because every morning the weather department do their work. If you receive a phone call reminding you the weather is going bad, you know, as a mayor, the weather is going to be rainy or stormy, right? Then the probability of a day being rainy is $\\frac{1}{2}$. Having the information of one event may increase our confidence about another, this is described by the conditional probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition 7 Conditional Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $A$ and $B$ be two events in probability space $(S,\\mathbb{B},P)$. The conditional probability of event $A$ given the knowledge that $B$ has already occurred, denoted as $P(A|B)$, is defined as \n",
    "$$P(A|B)=\\frac{P(A \\cap B)}{P(B)}$$\n",
    "provided that $P(B)>0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 7.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a classical example to illustrate this concept. We roll a dice, and record the number rolled, which is a random experiment, with the sample space being\n",
    "$$S=\\{1,2,3,4,5,6\\}$$\n",
    "\n",
    "Let's say $A$ is the event that number rolled is even, $B$ is that the number rolled is greater than 4, then\n",
    "$$A=\\{2,4,6\\}\\\\B=\\{5,6\\}$$\n",
    "\n",
    "Because every number in the sample space has the same likelihood to be rolled out, the probability of an event is the number of basic outcomes contained in the event divided by total number of basic outcomes, right?\n",
    "\n",
    "Then we can assign probability to $A$ and $B$, so that\n",
    "$$P(A)=\\frac{3}{6}\\\\P(B)=\\frac{2}{6}$$\n",
    "\n",
    "If, say, before we figuring out the exact number rolled, we know the number is an even, that is to say, we know beforehand that the event $B$ has happened. With this information, what's your confidence about the occurrence of event $A$? It must be greater than $\\frac{2}{6}$, because some information about the outcome is added to your consideration. \n",
    "\n",
    "You know that since the number rolled is an even, that is, the event $B$ has occurred, now the possible outcome is no longer the whole sample space, it becomes $\\{2,4,6\\}$.\n",
    "\n",
    "The event $A$ contains two basic outcomes $5$ and $6$, since the number rolled is an even, $5$ is impossible to happen, and the \"new sample space\" has three number, $6$ is one of them, *then the probability of $A$ with the knowledge that $B$ has happened* or *the probability of $A$ given $B$*, denoted as $P(A|B)$ is $\\frac{1}{3}$. \n",
    "\n",
    "We can also calculate this by definition. Conditional probability of $A$ given $B$ is the probability of $A$ and $B$ happening at the same time divided by the probability of the the event as condition, which is $B$. Be aware that any single basic outcome in an event happens means that event happens. So $A$ and $B$ happening at the same time requires that the basic outcomes is the **intersection** of $A$ and $B$, denoted as $A \\cap B$, that is $6$ in this case. It's just one out of six basic outcomes, so $P(A \\cap B)=\\frac{1}{6}$.\n",
    "\n",
    "The the event as condition $B$ contain 3 basic outcomes out of 6, so $P(B)=\\frac{3}{6}$.\n",
    "\n",
    "Combined together, we have\n",
    "$$P(A|B)=\\frac{P(A \\cap B)}{P(B)}=\\frac{\\frac{1}{6}}{\\frac{3}{6}}=\\frac{1}{3}$$\n",
    "\n",
    "The conditional probability of $A$ given $B$ is greater than the probability of $A$. How does the the event as condition increases the probability of another event? It's by filtering out the basic outcomes which violate the the event as condition which already happened."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplication Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By twisting the formula of conditional probability we can have a multiplication formula to calculate the joint probability of two events if we know the conditional probability and the probability of the event as condition.\n",
    "\n",
    "$$\\text{If} P(B)>0, \\text{then} P(A \\cap B)=P(A|B)P(B)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 7.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roll a coin twice. The sample space is $\\{HH,HT,TH,TT\\}$. The probability of rolling a head at least once is $\\frac{2}{4}$. The probability of rolling two heads given that rolling a head at least once is $\\frac{1}{2}$, then the probability of rollling a head at least once *and* rolling two heads is\n",
    "$$\\frac{2}{4} \\times \\frac{1}{2} = \\frac{1}{4}$$\n",
    "indicating the basic outcome $HH$ in the sample space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Multiplication Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the formula of multiplication rule that\n",
    "$$\\text{If} P(A)>0, \\text{then} P(A \\cap M)=P(M|A)P(A)$$\n",
    "\n",
    "Here, $M$ is just a notation for an event. It can be a statement of a single event, but also a combination of multiple events. Let's say, $M$ stands for events $B$ and $C$ happening at the same time, that is\n",
    "$$M=B \\cap C$$\n",
    "\n",
    "We can rewrite the formula as\n",
    "$$P(A \\cap B \\cap C)=P(B \\cap C|A)P(A)$$\n",
    "\n",
    "Note that $P(B \\cap C|A)$ is a conditional probability of joint event, we can extend it using multiplication rule again, which yields\n",
    "\n",
    "$$P(A \\cap B \\cap C)=P(C|B|A)P(B|A) P(A)$$\n",
    "which is equivalent to\n",
    "\n",
    "$$P(A \\cap B \\cap C)=P(C|A \\cap B)P(B|A) P(A)$$\n",
    "\n",
    "From this extended multiplication rule, we know that the joint probability forms a chain of conditional probability, which can be extended to $P(\\cap_{i=1}^n A_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule of Total Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the probability of event which is composed with multiple disjoint events is the summation of probability of each individual event, that is,\n",
    "$$P(\\cup_{i=1}^\\infty A_i)=\\sum_{i=1}^\\infty P(A_i), \\text{if} A_1, A_2, \\dots \\in \\mathbb{B} \\: \\text{are mutually exclusive}.$$\n",
    "\n",
    "If these disjoint events compose a sample space, that is to say, these events are **mutually exclusive**(disjoint) and **collective exhaustive**(all of them combined contains all elements in sample space), then, $\\left\\{A_{i}\\right\\}_{i=1}^{\\infty}$ is called a **partition** of sample space $S$, so that\n",
    "$$S=\\cup_{i=1}^\\infty A_i$$\n",
    "\n",
    "For probability of any event $E$ in the sample space, \n",
    "$$P(E)=P(E \\cap S)$$\n",
    "\n",
    "Break $S$ into one partition,\n",
    "$$P(E)=P(E \\cap \\cup_{i=1}^\\infty A_i)$$\n",
    "\n",
    "By distributivity laws, which are\n",
    "* $A \\cap(B \\cup C)=(A \\cap B) \\cup(A \\cap C)$\n",
    "* $A \\cup(B \\cap C)=(A \\cup B) \\cap(A \\cup C)$\n",
    "\n",
    "We have, \n",
    "\n",
    "$$P(E)=P(\\cup _{i=1}^\\infty(E \\cap A_i))=\\sum_{i=1}^\\infty P(E \\cap A_i)$$\n",
    "\n",
    "Incorporated into the multiplication rule, we have \n",
    "\n",
    "$$P(E)=P(\\cup _{i=1}^\\infty(E \\cap A_i))=\\sum_{i=1}^\\infty P(E \\cap A_i)=\\sum_{i=1}^\\infty P(E|A_i)P(A_i)$$\n",
    "\n",
    "which is called **rule of total probability**.\n",
    "\n",
    "The intuition is that we can break the sample space into multiple events, and use these events as conditions, calculate conditional probability of an event given each condition and sum them up to attain the probability of the event."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
